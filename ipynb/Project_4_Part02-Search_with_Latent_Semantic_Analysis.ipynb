{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. clean the input string the same way you cleaned your data\n",
    "1. use your tfidf or count-vectorizer to transform your search query (transform)\n",
    "1. use your TruncatedSVC to transform your document-term matrix\n",
    "1. use cosine similarity OR nearest neighbors (or both) to find the top 5 most similar documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the same text cleaner used to clean the data to the search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('/home/jovyan/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import library.db_helper as db\n",
    "import library.functions as fy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_query = 'support vector machine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_search = fy.text_cleaner(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'support vector machine'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Text from the Page table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT text\n",
    "FROM page\n",
    "'''\n",
    "\n",
    "X = db.query_to_dataframe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is not a wikipedia article it is an indiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this article has multiple issues please help i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine learning anddata miningproblemsclassif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for the journal see machine learning journal m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the following outline is provided as an overvi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  this is not a wikipedia article it is an indiv...\n",
       "1  this article has multiple issues please help i...\n",
       "2  machine learning anddata miningproblemsclassif...\n",
       "3  for the journal see machine learning journal m...\n",
       "4  the following outline is provided as an overvi..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54972729</td>\n",
       "      <td>this is not a wikipedia article it is an indiv...</td>\n",
       "      <td>user custintelmngt sandbox customer intelligen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43385931</td>\n",
       "      <td>this article has multiple issues please help i...</td>\n",
       "      <td>data exploration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49082762</td>\n",
       "      <td>machine learning anddata miningproblemsclassif...</td>\n",
       "      <td>list of datasets for machine learning research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>233488</td>\n",
       "      <td>for the journal see machine learning journal m...</td>\n",
       "      <td>machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53587467</td>\n",
       "      <td>the following outline is provided as an overvi...</td>\n",
       "      <td>outline of machine learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pid                                               text  \\\n",
       "0  54972729  this is not a wikipedia article it is an indiv...   \n",
       "1  43385931  this article has multiple issues please help i...   \n",
       "2  49082762  machine learning anddata miningproblemsclassif...   \n",
       "3    233488  for the journal see machine learning journal m...   \n",
       "4  53587467  the following outline is provided as an overvi...   \n",
       "\n",
       "                                               title  \n",
       "0  user custintelmngt sandbox customer intelligen...  \n",
       "1                                   data exploration  \n",
       "2     list of datasets for machine learning research  \n",
       "3                                   machine learning  \n",
       "4                        outline of machine learning  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT * \n",
    "FROM page\n",
    "'''\n",
    "page = db.query_to_dataframe(query)\n",
    "page.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Latent Semantic Analysis - Article Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJxLyslPzk7JTExXqOZSUFAqSixXSEksSVRS0LVTUCpILCpOhTCTc1IT85SsQWogTLBoSGpRrq5LfnJpbmpeiUJMnm9iSVFmBUQZDjmwvuAwFwjDM68ktaigKBWkICi1uDSnpBiouxYAYKwuOg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Vetorize the Search Term and the Corpus (X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the tfidf vectorizer and apply it to the corpus and to the searh term\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit and transform the corpus into a sparse matrix using tfidf vectorizer\n",
    "doc_term_matrix = tfidf_vectorizer.fit_transform(X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the search term to a vector (do not fit)\n",
    "search_term_vec = tfidf_vectorizer.transform([search_query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_vectorizer (search_query, min_df=1):\n",
    "    tfidf_vec = TfidfVectorizer(stop_words = 'english', min_df=min_df)\n",
    "    doc_term_matrix = tfidf_vec.fit_transform(X['text'])\n",
    "    search_query_vec = tfidf_vec.transform([search_query])\n",
    "    return doc_term_matrix, search_query_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use SVD to reduce dimensionality for the sparse document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate TruncatedSVD\n",
    "SVD = TruncatedSVD(n_components=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit & transform the document term matrix to reduce the dimensionality of the doc_term_matrix\n",
    "latent_semantic_analysis = SVD.fit_transform(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the vectorized search term (do not fit)\n",
    "search_term_vec_lsa = SVD.transform(search_term_vec)\n",
    "type(search_term_vec_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVD_lsa (search_query, n_components=300):\n",
    "    SVD = TruncatedSVD(n_components=n_components)\n",
    "    doc_term_matrix, search_query_vec = tfidf_vectorizer (search_query)\n",
    "    lsa_doc_term = SVD.fit_transform(doc_term_matrix)\n",
    "    search_query_lsa = SVD.transform(search_query_vec)\n",
    "    return lsa_doc_term, search_query_lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Apply sklearn's cosine_similiarity to return article matches for the given search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06200576,  0.08903066,  0.05471174, ...,  0.03365297,\n",
       "       -0.00027005, -0.01681301])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_arr = cos_sim(latent_semantic_analysis, search_term_vec_lsa).ravel()\n",
    "cos_sim_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(cos_sim_arr)[:-6:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2787, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2787, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.shape # page table in my SQL db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relevance vector machine',\n",
       " 'relevance vector machine',\n",
       " 'corinna cortes',\n",
       " 'libsvm',\n",
       " 'international conference on machine learning']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(page['title'].iloc[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_related_articles (search_query, n_results=5):\n",
    "    lsa_doc_term, search_query_lsa = SVD_lsa(search_query)\n",
    "    cos_sim_arr = cosine_similarity(lsa_doc_term, search_query_lsa).ravel()\n",
    "    \n",
    "    first_term = -1*(n_results) - 1 \n",
    "    np.argsort(cos_sim_arr)[:first_term: -1]\n",
    "    related_articles = list(page['title'].iloc[indices])\n",
    "    return related_articles   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relevance vector machine',\n",
       " 'relevance vector machine',\n",
       " 'corinna cortes',\n",
       " 'libsvm',\n",
       " 'international conference on machine learning']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grab_related_articles(\"oracle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.A Write functions to perform this on all types of search queries\n",
    "#### 4.B Write a class to run these different steps \n",
    "    - tfidf (vectorize search term & create vectorized document)\n",
    "    - lsa (complete lsa)\n",
    "    - return the 5 most relevant articles (use a method like cosine similiarty, nearest neighbor if I have time to compare)\n",
    "#### 4.C Build a model pipeline to predict which Wikipedia articles are most relevant for the search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tfidf_lsa:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "    def tfdif_vectorizor:\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize (text):\n",
    "    clean_text = text_cleaner(text)\n",
    "    return clean_text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
