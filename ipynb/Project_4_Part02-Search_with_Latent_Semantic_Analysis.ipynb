{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the same text cleaner used to clean the data to the search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('/home/jovyan/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import library.db_helper as db\n",
    "import library.functions as fy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search = 'support vector machine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_search = fy.text_cleaner(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'support vector machine'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab Text from the Page table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT text\n",
    "FROM page\n",
    "'''\n",
    "\n",
    "X = db.query_to_dataframe(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this article is an orphan as no other articles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this article has multiple issues please help i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this article has multiple issues please help i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a block diagram of the cmac system for a singl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>choose and book was an e booking software appl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  this article is an orphan as no other articles...\n",
       "1  this article has multiple issues please help i...\n",
       "2  this article has multiple issues please help i...\n",
       "3  a block diagram of the cmac system for a singl...\n",
       "4  choose and book was an e booking software appl..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48844125</td>\n",
       "      <td>this article is an orphan as no other articles...</td>\n",
       "      <td>structured sparsity regularization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2506529</td>\n",
       "      <td>this article has multiple issues please help i...</td>\n",
       "      <td>cellular neural network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33085387</td>\n",
       "      <td>this article has multiple issues please help i...</td>\n",
       "      <td>computhink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8160211</td>\n",
       "      <td>a block diagram of the cmac system for a singl...</td>\n",
       "      <td>cerebellar model articulation controller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1917193</td>\n",
       "      <td>choose and book was an e booking software appl...</td>\n",
       "      <td>choose and book</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pid                                               text  \\\n",
       "0  48844125  this article is an orphan as no other articles...   \n",
       "1   2506529  this article has multiple issues please help i...   \n",
       "2  33085387  this article has multiple issues please help i...   \n",
       "3   8160211  a block diagram of the cmac system for a singl...   \n",
       "4   1917193  choose and book was an e booking software appl...   \n",
       "\n",
       "                                      title  \n",
       "0        structured sparsity regularization  \n",
       "1                   cellular neural network  \n",
       "2                                computhink  \n",
       "3  cerebellar model articulation controller  \n",
       "4                           choose and book  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT * \n",
    "FROM page\n",
    "'''\n",
    "page = db.query_to_dataframe(query)\n",
    "page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2439"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page['pid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2439, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      structured sparsity regularization\n",
       "1                                 cellular neural network\n",
       "2                                              computhink\n",
       "3                cerebellar model articulation controller\n",
       "4                                         choose and book\n",
       "5                                                    codi\n",
       "6                                             clinicalkey\n",
       "7                                    competitive learning\n",
       "8       user custintelmngt sandbox customer intelligen...\n",
       "9                                        data exploration\n",
       "10         list of datasets for machine learning research\n",
       "11                                       machine learning\n",
       "12                            outline of machine learning\n",
       "13                                      random projection\n",
       "14                        statistical relational learning\n",
       "15                                 stochastic block model\n",
       "16                                       draft alldone io\n",
       "17                                          apache allura\n",
       "18                                      artemis software \n",
       "19                                        aurigo software\n",
       "20                                                axosoft\n",
       "21                                              bitbucket\n",
       "22                                    bug tracking system\n",
       "23        capital program and project management software\n",
       "24                                        sprog software \n",
       "25                                       accuracy paradox\n",
       "26                                  action model learning\n",
       "27                      active learning machine learning \n",
       "28                           adversarial machine learning\n",
       "29                                                   aiva\n",
       "                              ...                        \n",
       "2409                                    lotus foundations\n",
       "2410                                        lotus impress\n",
       "2411                                         metro format\n",
       "2412                               microsoft interconnect\n",
       "2413                                    microsoft office \n",
       "2414                   microsoft office macintosh edition\n",
       "2415                          microsoft office accounting\n",
       "2416                                       mini office ii\n",
       "2417                               plan calendar program \n",
       "2418                                               mondex\n",
       "2419                                           moneydance\n",
       "2420                             office genuine advantage\n",
       "2421                                         openmeetings\n",
       "2422                                          pivot chart\n",
       "2423                       postscript printer description\n",
       "2424                     reflex building design software \n",
       "2425                                   reliable messaging\n",
       "2426                                      sage accounting\n",
       "2427                                    salary calculator\n",
       "2428                      sap transport management system\n",
       "2429                                       sasi software \n",
       "2430                                        sentinel fbi \n",
       "2431                                         sierra chart\n",
       "2432                     sonata building design software \n",
       "2433                                            supercalc\n",
       "2434                             taurus share settlement \n",
       "2435                                               tress \n",
       "2436                                 ibm unica netinsight\n",
       "2437                                          wang office\n",
       "2438                                        whiteboarding\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page['title'].apply(lambda x : fy.text_cleaner(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Latent Semantic Analysis - Article Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJxLyslPzk7JTExXqOZSUFAqSixXSEksSVRS0LVTUCpILCpOhTCTc1IT85SsQWogTLBoSGpRrq5LfnJpbmpeiUJMnm9iSVFmBUQZDjmwvuAwFwjDM68ktaigKBWkICi1uDSnpBiouxYAYKwuOg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Vetorize the Search Term and the Corpus (X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_vectorizer (search_query, min_df=1):\n",
    "    tfidf_vec = TfidfVectorizer(stop_words = 'english', min_df=min_df)\n",
    "    doc_term_matrix = tfidf_vec.fit_transform(X['text'])\n",
    "    search_query_vec = tfidf_vec.transform([search_query])\n",
    "    return doc_term_matrix, search_query_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use SVD to reduce dimensionality for the sparse document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVD_lsa (search_query, n_components=300, min_df=1):\n",
    "    SVD = TruncatedSVD(n_components=n_components)\n",
    "    doc_term_matrix, search_query_vec = tfidf_vectorizer (search_query, min_df = min_df)\n",
    "    \n",
    "    lsa_doc_term = SVD.fit_transform(doc_term_matrix)\n",
    "    search_query_lsa = SVD.transform(search_query_vec)\n",
    "    \n",
    "    return lsa_doc_term, search_query_lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Apply sklearn's cosine_similiarity to return article matches for the given search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2787, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_related_articles (search_query, n_results=5, n_components = 300, min_df=1):\n",
    "    lsa_doc_term, search_query_lsa = SVD_lsa(search_query, n_components=n_components, min_df=min_df)\n",
    "    cos_sim_arr = cosine_similarity(lsa_doc_term, search_query_lsa).ravel()\n",
    "    \n",
    "    first_term = -1*(n_results) - 1 \n",
    "    indices = np.argsort(cos_sim_arr)[:first_term: -1]\n",
    "    \n",
    "    related_articles = list(page['title'].iloc[indices])\n",
    "    return related_articles   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive bayes classifier',\n",
       " 'averaged one dependence estimators',\n",
       " 'ensemble learning',\n",
       " 'labeled data',\n",
       " 'bayesian network']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grab_related_articles(\"bayes\", n_results=5, n_components = 400, min_df = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.A Write functions to perform this on all types of search queries\n",
    "#### 4.B Write a class to run these different steps \n",
    "    - tfidf (vectorize search term & create vectorized document)\n",
    "    - lsa (complete lsa)\n",
    "    - return the 5 most relevant articles (use a method like cosine similiarty, nearest neighbor if I have time to compare)\n",
    "#### 4.C Build a model pipeline to predict which Wikipedia articles are most relevant for the search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tfidf_lsa:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "    def tfdif_vectorizor:\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize (text):\n",
    "    clean_text = text_cleaner(text)\n",
    "    return clean_text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
